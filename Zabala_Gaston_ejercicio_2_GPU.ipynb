{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zabala_Gaston_ejercicio_2_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZabalaGaston/HPC/blob/main/Zabala_Gaston_ejercicio_2_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoYPFWcielY3"
      },
      "source": [
        "#1 Introducción\n",
        "\n",
        "Una matriz traspuesta es el resultado de reordenar la matriz original mediantel cambio de filas por columnas y las columnas por filas en una nueva matriz. [3][2]\n",
        "\n",
        "\n",
        "\n",
        "<center>(A^t){ij}=A{ji},1 <= m, 1 <= j <= n </center> \n",
        "\n",
        "En este cuaderno, dejaré plasmado el algoritmo para trasponer una matriz cuadrada, utilizando GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32YB71STfPcy"
      },
      "source": [
        "#2 Armado del ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GLsQ34ysP4_"
      },
      "source": [
        "---\n",
        "## 2.1 Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ropgS48tsRTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48add7f1-7d18-4baf-9b71-ba66aea578de"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 8.9MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=620900 sha256=18a1a8cf00d10cf9527dd5b612b66a464512af00135f1867a37ef11809b4620d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=0e7f762753702319f2ade87b69062f7405bab9a4c23a43aa9137a682c5625713\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt4Pea0Psrx_"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n",
        "Ejecución del algoritmo para trasponer una matriz utilizando GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_uVXVJjz_Jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13d0584-a26e-4cdd-8722-4e4cdfd7b0c2"
      },
      "source": [
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "#@title 3.1.1 Ingrese el orden { vertical-output: true }\n",
        "\n",
        "ordenMatriz =   10000#@param {type:\"integer\"}\n",
        "\n",
        "# --------------------------------------------\n",
        "%matplotlib inline\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "# --------------------------------------------\n",
        "#Funciones\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# Definición de función para crear matriz\n",
        "\n",
        "def crearMatriz(orden):\n",
        "  m = np.random.randint(100, 1000, (ordenMatriz, ordenMatriz))\n",
        "  return m.astype( np.float32())\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void trasponerMatriz( int orden, float *mo, float *mt )\n",
        "{\n",
        "  // Calculo las coordenadas del Thread en dos dimensiones.\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  int idy = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "\n",
        "  // Verifico que los Thread estén dentro del orden de la matriz.\n",
        "  if( idx < orden && idy < orden )\n",
        "  {\n",
        "    int indexMt =  idy * orden + idx;\n",
        "    int indexMo =  idx * orden + idy;\n",
        "\n",
        "    mt[indexMt] = mo[indexMo];\n",
        "  }\n",
        "}\n",
        "\"\"\") \n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "# Creo las matrices\n",
        "try:\n",
        "\n",
        "  if ordenMatriz <= 0:\n",
        "    raise ValueError(\"Error: el orden de la matriz debe ser mayor a 0\");\n",
        "  \n",
        "  matriz_cpu = crearMatriz(ordenMatriz)\n",
        "  matrizTraspuesta_cpu = crearMatriz(ordenMatriz)\n",
        "\n",
        "  # Reservo los 2 vectores en GPU\n",
        "  matriz_gpu = cuda.mem_alloc( matriz_cpu.nbytes )\n",
        "  matrizTraspuesta_gpu = cuda.mem_alloc( matrizTraspuesta_cpu.nbytes )\n",
        "\n",
        "  # GPU - Copio la memoria al GPU.\n",
        "  cuda.memcpy_htod( matriz_gpu, matriz_cpu )\n",
        "  cuda.memcpy_htod( matrizTraspuesta_gpu, matrizTraspuesta_cpu )\n",
        "\n",
        "  # CPU - Genero la función kernel.\n",
        "  kernel = module.get_function(\"trasponerMatriz\")\n",
        "\n",
        "  dim_hilo_x = 16\n",
        "  dim_bloque_x = np.int( (ordenMatriz+dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "  dim_hilo_y = 19\n",
        "  dim_bloque_y = np.int( (ordenMatriz+dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "  tiempo_traspuesta = datetime.now()\n",
        "\n",
        "  kernel( np.int32(ordenMatriz), matriz_gpu, matrizTraspuesta_gpu, block=( dim_hilo_x, dim_hilo_y, 1 ), grid=(dim_bloque_x, dim_bloque_y,1) )\n",
        "\n",
        "  tiempo_traspuesta = datetime.now() - tiempo_traspuesta\n",
        "\n",
        "  # GPU - Copio el resultado desde la memoria GPU.\n",
        "  cuda.memcpy_dtoh( matrizTraspuesta_cpu, matrizTraspuesta_gpu )\n",
        "\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "  print(\"Tiempo Total: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "  print(\"Tiempo Trasponer: \", tiempo_en_ms( tiempo_traspuesta ), \"[ms]\" )\n",
        "\n",
        "  print(\"\\n\\nMatriz original\\n\", matriz_cpu)\n",
        "  print(\"\\nMatriz traspuesta\\n\",matrizTraspuesta_cpu)\n",
        "\n",
        "except ValueError as vr:\n",
        "  print(vr)\n",
        "except Exception as e: \n",
        "  print(e.args)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tiempo Total:  1904.423 [ms]\n",
            "Tiempo Trasponer:  0.11 [ms]\n",
            "\n",
            "\n",
            "Matriz original\n",
            " [[581. 883. 859. ... 883. 788. 982.]\n",
            " [638. 140. 184. ... 991. 957. 208.]\n",
            " [285. 720. 974. ... 233. 495. 250.]\n",
            " ...\n",
            " [427. 916. 434. ... 920. 543. 632.]\n",
            " [862. 827. 493. ... 951. 214. 134.]\n",
            " [628. 402. 230. ... 700. 895. 184.]]\n",
            "\n",
            "Matriz traspuesta\n",
            " [[581. 638. 285. ... 427. 862. 628.]\n",
            " [883. 140. 720. ... 916. 827. 402.]\n",
            " [859. 184. 974. ... 434. 493. 230.]\n",
            " ...\n",
            " [883. 991. 233. ... 920. 951. 700.]\n",
            " [788. 957. 495. ... 543. 214. 895.]\n",
            " [982. 208. 250. ... 632. 134. 184.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqAv4Gt7qRrh"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos\n",
        "\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      | pip install pycuda    | Instalar en el cuaderno los driver de CUDA para Python.\n",
        "CPU      |  import                | Importar los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Tomar el tiempo actual.\n",
        "CPU      |  crearMatriz()         | Crear y cargar valores a la matriz original.\n",
        "CPU      |  crearMatriz()         | Crear matriz traspuesta (matrizTraspuesta).\n",
        "**GPU**  |  cuda.mem_alloc()      | Reservar la memoria para las matrices en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copiar los valores en crudo de las matrices al GPU.\n",
        "CPU      |  SourceModule()        | Posee el código del kernel.\n",
        "CPU      |  module.get_function() | Conviertir el texto del kernel en funcion de Python.\n",
        "CPU      |  dim_hilo_x, dim_hilo_y| Calcular las dimensiones para la ejecuciòn de 2D.\n",
        "**GPU**  |  kernel()              | Ejecutar el kernel en GPU, enviando los parametros (Traspone la matriz).\n",
        "CPU      | datetime.now() - tiempo_traspuesta | Calcular tiempo total en trasponerMatriz. (GPU(\n",
        "CPU      | cuda.memcpy_dtoh()     | Copiar desde la memoria GPU al CPU.\n",
        "CPU      |  datetime.now() - tiempo_total | Calcular el tiempo total.\n",
        "CPU      |  tiempo_en_ms( time ) | Transformar tiempos en milisegundos.\n",
        "CPU      |  print()               | Mostrar estadísticas.\n",
        "CPU      |  print()            | Mostrar matriz original y matriz traspuesta.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtiz4_7bmaDe"
      },
      "source": [
        "---\n",
        "# 5 Conclusiones\n",
        "\n",
        "Realicé la ejecución 10 veces para una matriz cuadrada de 10000 x 10000, obteniendo los siguientes resultados:\n",
        "\n",
        "Tiempo Total:  1998.161 [ms] | Tiempo Trasponer:  0.174 [ms]<br>\n",
        "Tiempo Total:  1911.462 [ms] | Tiempo Trasponer:  0.120 [ms]<br>\n",
        "Tiempo Total:  1867.214 [ms] | Tiempo Trasponer:  0.112 [ms]<br>\n",
        "Tiempo Total:  1897.369 [ms] | Tiempo Trasponer:  0.124 [ms]<br>\n",
        "Tiempo Total:  1925.017 [ms] | Tiempo Trasponer:  0.119 [ms]<br>\n",
        "Tiempo Total:  1944.206 [ms] | Tiempo Trasponer:  0.128 [ms]<br>\n",
        "Tiempo Total:  1899.049 [ms] | Tiempo Trasponer:  0.126 [ms]<br>\n",
        "Tiempo Total:  1924.625 [ms] | Tiempo Trasponer:  0.123 [ms]<br>\n",
        "Tiempo Total:  1939.246 [ms] | Tiempo Trasponer:  0.130 [ms]<br>\n",
        "Tiempo Total:  1904.423 [ms] | Tiempo Trasponer:  0.110 [ms]<br>\n",
        "\n",
        "\n",
        "Podemos observar, que los tiempos de ejecución promedio [1920.8 ms] del programa son muchos **menores** a los obtenidos sin utilizar GPU. [56187.5 ms] , esto se debe a que al usar GPU la matriz se va recorriendo simultáneamente en varios threads.\n",
        "\n",
        "El punto más relevante en este ejercicio es la utilización de la función Kernel, la cuál nos permite ejecutar el algoritmo en dos dimensiones utilizando hilos.\n",
        "\n",
        "En cuanto a lecciones aprendidas, comprendí el funcionamiento de hilos y la utilización del módulo CUDA.\n",
        "Como mejora, se podrían agregar gráficos ilustrativos de las métricas obtenidas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufDYy0LPmbYH"
      },
      "source": [
        "----\n",
        "# 6 Bibliografía\n",
        "\n",
        "[1] Tutorial Point Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[2] Matriz traspuesta: [Enlace](https://es.wikipedia.org/wiki/Matriz_transpuesta)\n",
        "\n",
        "[3] Traspuesta: [Enlace](https://economipedia.com/definiciones/matriz-traspuesta.html#:~:text=Una%20matriz%20traspuesta%20es%20el,filas%20en%20una%20nueva%20matriz)"
      ]
    }
  ]
}